{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30751bce-c8b2-4938-94f4-aa69ae354731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a624888-e6ab-4903-98fc-6b119b6eee3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a798701-a03c-4b76-824e-2b7cad3b274e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaead920-3109-4847-a8f4-0941b1697b42",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "\n",
    "El \"perceptrón\" es una de las arquitecturas de RNA más sencillas, creada en 1957 por Frank Rosenblatt. Se basa en una neurona artificial ligeramente diferente llamada Unidad Lógica Umbral (ULU).\n",
    "\n",
    "Las entradas y salidas son números (en lugar de activadores binarios) y cada conexión de entrada está asociada a un peso.\n",
    "\n",
    "La ULU cálcula una suma ponderada de sus entrada ($ x = w_1 x_1 + w_2 x_2 + ... + w_n x_n = X^T W $) y luego aplica una función escalonada a esa suma para producir el resultado (output): $ h_w (X) = step(z) $, donde $ z = X^T W $ \n",
    "\n",
    "<img src=\"https://quantstartmedia.s3.amazonaws.com/images/article-images/articles/introduction-to-artificial-neural-networks-and-the-perceptron/perceptron.png\"  width=\"500\" height=\"500\">\n",
    "\n",
    "La función escalonada que se utiliza frecuentemente en los perceptrones es la función escalonada Heaviside\n",
    "\n",
    "$ Heavise(z) = $ { $ 0 $ si $ z < 0 $ ; $ 1 $ si $ z \\geq 0 $\n",
    "\n",
    "Un perceptrón consta de una sola capa ULU. Cuando todas las neuronas de una capa estan conectadas a todas las neuronas de la capa anterior (neuronas de entrada), estamos ante una capa completamente conectada o densa.\n",
    "\n",
    "Se suele añadir una capa de sesgo adicional ($ x_0 = 1 $): representada por una neurona de sesgo que produce 1 todo el tiempo.\n",
    "\n",
    "La siguiente imagen representa un perceptróm con dos entradas y tres salidas, este perceptrón puede clasificar simultaneamente tres clases binarias diferentes, siendo un clasificador multisalida.\n",
    "\n",
    "<img src=\"https://www.danli.org/2021/06/21/hands-on-machine-learning-keras/chapters/10/10.5.png\"  width=\"500\" height=\"500\">\n",
    "\n",
    "Se puede cálcular con eficiencia la salida de una capa de neurona para varias instancias:\n",
    "\n",
    "$ h_{W, b} (X) = \\phi (XW + b) $\n",
    "\n",
    "En la ecuación tenemos:\n",
    "\n",
    "- $X$: Matriz de características de entrada. Una fila por instancia y una columna por característica.\n",
    "- $W$: Matriz de pesos de conexión, excepto la neurona de sesgo. Tiene una fila por neurona de entrada y una columna por neurona artificial en la capa.\n",
    "- $b$: Vector de sesgo, que contiene todos los pesos de conexión entre la neurona de sesgo y las neuronas artificiales.\n",
    "- $\\phi$: Función de activación: cuando las neuronas artificiales son ULU, es una función escalonada pero hay otras.\n",
    "\n",
    "## ¿Cómo se entrena un perceptrón?\n",
    "\n",
    "El algoritmo de entrenamiento del perceptrón se basa en la regla de Hebb de su libro de 1949, Organización de la Conducta (Debate), donde se sugiere que cuando una neurona biologica activa a otra, con frecuencia la conexión entre estas dos se fortalece. \n",
    "\n",
    "Los perceptrones se entrenan con una variación de esta regla que tiene en cuenta el error cometido por la red cuando hace una predicción. El perceptrón recibe las instancias de entrenamiento y realiza sus predicciones para cada instancia, Por cada neurona de salida que produce una predicción erronea, refueza los pesos de conexión a partir de las entradas que habrían contribuido a la predicción correcta. La regla de aprendizaje es la siguiente:\n",
    "\n",
    "$ w_{i,j}^{Siguiente} =  w_{i,j} + \\eta(y_j - \\hat{y}_j) x_i $\n",
    "\n",
    "- $w_{i, j}$: El peso de conexión entre la i-esima neurona de entrada y la j-esima neurona de salida.\n",
    "- $x_i$: El valor de la i-esima neurona de salida para la instancia de entrenamiento actual.\n",
    "- $\\hat{y}_j$: El valor de salida de la j-esima neurona para la instancia de entrenamiento actual.\n",
    "- $y_i$: El valor objetivo de la j-esima neurona para la instancia de entrenamiento actual.\n",
    "- $\\eta$: Tasa de aprendizaje.\n",
    "\n",
    "El límite de decisión de cada neurona es lineal, así que los perceptrones son incapaces de aprender patrones complejos. Sin embargo, las instancias de entrenamiento son separables linealmente, lo que permite converger a uan solución.\n",
    "\n",
    "La instancia en Scikit-Learn orfdere una solución para el perceptrón."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9c9938a-a7c2-44c0-95ed-cf936150351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a818088d-af61-487d-980e-c114ea6858ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data[:, (2,3)] # longitud de pétalo, anchura del pétalo\n",
    "y = (iris.target == 0).astype(np.int32) # ¿Iris setosa?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d414901c-c5f8-427a-806a-06576ac573cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Perceptron()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Perceptron</label><div class=\"sk-toggleable__content\"><pre>Perceptron()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Perceptron()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c4af77b-db24-4a7f-88d4-eb5e00aadcea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict([[2, 0.5]])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc85cdfa-1aff-4d30-8323-6354903a7bb6",
   "metadata": {},
   "source": [
    "Los perceptrones no permiten obtener probabilidades, sino que hacen predicciones basándose en un umbral duro, por eso es deseable una regresión logistica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129bc133-372e-462f-9a7a-c0994f50e7ec",
   "metadata": {},
   "source": [
    "# Perceptrón Multicapa (PMC) y la retropropagación\n",
    "\n",
    "Un PMC consta de una capa de entrada (transito), una o varias capas de ULU (llamada capas ocultas) y una última capa de ULU (capa de salida).Las capas cercanas a la entrada suelen llamarse \"capas inferiores\", y las próximas a la salida \"capas superiores\". Cada capa, excepto la de salida, incluye una neurona de sesgo y está completamente conectada a la siguiente capa.\n",
    "\n",
    "<img src=\"https://www.danli.org/2021/06/21/hands-on-machine-learning-keras/chapters/10/10.9.png\"  width=\"500\" height=\"500\">\n",
    "\n",
    "Cuando una RNA contiene una pila profunda de capas ocultas, se habla de una Red Neuronal Profunda (RNP). En el campo del Deep Learning se estudia RNA y, en general, modelos que contienen pilas profundas de cálculos. \n",
    "\n",
    "## Retropropagación\n",
    "\n",
    "Es un método de entrenamiento de los PMC, propuesto en 1986, que introduce la retropropagación, similar a las técnicas de gradiente descendiente: en solo dos pasos (hacía delante y atrás) la red puede cálcular el gradiente de error de la red respecto a cada parámetro del modelo. En otras palabras, puede averiguar cómo habría que ajustar cada peso de conexión y cada término de sesgo para reducir el error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249b29c0-3d37-4678-9a78-d571a72aa6cf",
   "metadata": {},
   "source": [
    "# Extracción de datos Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ef4ac95-0c5e-47de-a51c-61fb2b22fe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de datos similar a MNIST, con 70.000 imagenes en escala de grises de 28x28 pixels y 10 clases de articulos de moda\n",
    "fashion_mnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e557dc30-40c0-4e83-bf50-acd29423f9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50649f8f-4a87-4a78-b1ef-88a7fc9ad29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a40b96e-d694-4346-93ad-06f4252e26fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cdcd7c4-3efe-464c-a42a-6db6c6c3c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando conjunto de validación\n",
    "# Se escala la densidad de pixeles hasta el rango 0-1, dividiendo entre 255\n",
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ac63c0d-7cb0-4228-8615-f6f992fa7f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se asocia las etiquetas númericas con nombres representativos\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8143c455-eb5c-4907-b830-07375ca657d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5772b6bc-09a3-40db-a6bd-f4ca4394b56e",
   "metadata": {},
   "source": [
    "# Creación del modelo con la API Secuencial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5bdea8-9878-4098-a93a-5c97f7b56611",
   "metadata": {},
   "source": [
    "Crea el modelo Sequential. es el tipo más sencillo de modelos en Keras para RNA. \n",
    "\n",
    "Consta de una sola única pila de capas conectadas secuencialmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59e52df-b856-40c5-b5f5-b28184b1eb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25987eb7-0dea-4641-a8df-39ddd0189242",
   "metadata": {},
   "source": [
    "Se construye la primera capa y se añade al modelo. Capa Flatten convierte la entrada de imagen en una matriz 1D. \n",
    "\n",
    "Esta capa no tiene parametros, solo existe para el preprocesamiento.\n",
    "\n",
    "Dado que es la primera capa, se debe especificar el input_shape, que da la forma de la instancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15914e46-3a7e-4732-bd12-955907006cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Flatten(input_shape[28, 28]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c16384b-d33f-4105-b144-0485d2c8f4ff",
   "metadata": {},
   "source": [
    "Se añade una capa Dense oculta con 300 neuronas, que utiliza la función de activación ReLU. \n",
    "\n",
    "Cada capa Dense administra su propia matriz de pesos, que contiene los pesos de conexión entre las neuronas y sus salidas.\n",
    "\n",
    "También gestiona un vector de términos de sesgo (uno por neurona), cuando recibe datos de entrada, computa la siguiente ecuación:\n",
    "\n",
    "$ h_{W,b}(X) = \\Phi(X W + b) $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a10c15-9bd4-4b92-bdc4-4ddc18f17d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(300, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab52447-426f-4b0c-828d-81a3dde65f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(100, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f6be68-2618-4b87-a82d-740e3123cac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(10, activation = 'softmax'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
